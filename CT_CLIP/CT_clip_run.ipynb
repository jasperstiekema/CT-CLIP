{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fdb688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch version: 2.1.0+cu121\n",
      "CT-CLIP imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "# ... rest of your imports and code\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pydicom\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import zoom\n",
    "import nibabel as nib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "from ct_clip.ct_clip import CTCLIP\n",
    "print(\"CT-CLIP imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c53b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patients: 100%|██████████| 2/2 [00:17<00:00,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\metadata.csv\n",
      "Processed 5 volumes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dicom_dir = r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\TEST CT SCANS\"\n",
    "root_nifti_dir = r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\NIFTI CT SCANS\"\n",
    "\n",
    "patient_dirs = [d for d in os.listdir(root_dicom_dir) if os.path.isdir(os.path.join(root_dicom_dir, d))]\n",
    "\n",
    "metadata_records = []\n",
    "\n",
    "for patient_id in tqdm(patient_dirs, desc=\"Patients\"):\n",
    "    patient_dicom_path = os.path.join(root_dicom_dir, patient_id)\n",
    "    patient_nifti_path = os.path.join(root_nifti_dir, patient_id)\n",
    "    os.makedirs(patient_nifti_path, exist_ok=True)\n",
    "\n",
    "    scan_dirs = [d for d in os.listdir(patient_dicom_path) if os.path.isdir(os.path.join(patient_dicom_path, d))]\n",
    "\n",
    "    for scan_name in tqdm(scan_dirs, desc=f\"Scans for patient {patient_id}\", leave=False):\n",
    "        scan_dicom_path = os.path.join(patient_dicom_path, scan_name)\n",
    "\n",
    "        dcm_files = [os.path.join(scan_dicom_path, f) for f in os.listdir(scan_dicom_path) if f.endswith('.dcm')]\n",
    "\n",
    "        slices = [pydicom.dcmread(f) for f in dcm_files]\n",
    "        slices.sort(key=lambda x: int(getattr(x, 'InstanceNumber', 0)))\n",
    "\n",
    "        volume = np.stack([s.pixel_array for s in slices])\n",
    "\n",
    "        # Extract DICOM metadata from first slice\n",
    "        first_slice = slices[0]\n",
    "        slope = float(getattr(first_slice, 'RescaleSlope', 1.0))\n",
    "        intercept = float(getattr(first_slice, 'RescaleIntercept', 0.0))\n",
    "\n",
    "        pixel_spacing = first_slice.PixelSpacing  # usually [row_spacing, col_spacing]\n",
    "        xy_spacing = float(pixel_spacing[0])  # assuming isotropic in-plane spacing\n",
    "        z_spacing = float(getattr(first_slice, 'SliceThickness', 1.0))\n",
    "\n",
    "        # Prepare affine transformation for NIfTI\n",
    "        spacing = [xy_spacing, xy_spacing, z_spacing]\n",
    "        affine = np.diag(spacing + [1])\n",
    "\n",
    "        # Save NIfTI file\n",
    "        nifti_filename = f\"{scan_name}.nii.gz\"\n",
    "        nifti_path = os.path.join(patient_nifti_path, nifti_filename)\n",
    "\n",
    "        nifti_img = nib.Nifti1Image(volume, affine=affine)\n",
    "        nib.save(nifti_img, nifti_path)\n",
    "\n",
    "        # Collect metadata\n",
    "        metadata_records.append({\n",
    "            'PatientID': patient_id,\n",
    "            'ScanName': scan_name,\n",
    "            'VolumeName': nifti_filename,\n",
    "            'RescaleSlope': slope,\n",
    "            'RescaleIntercept': intercept,\n",
    "            'XYSpacing': xy_spacing,\n",
    "            'ZSpacing': z_spacing\n",
    "        })\n",
    "\n",
    "# Save metadata to CSV\n",
    "metadata_df = pd.DataFrame(metadata_records)\n",
    "metadata_csv_path = os.path.join(r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\", \"metadata.csv\")\n",
    "metadata_df.to_csv(metadata_csv_path, index=False)\n",
    "\n",
    "print(f\"Metadata saved to {metadata_csv_path}\")\n",
    "print(f\"Processed {len(metadata_records)} volumes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0c9418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing NIfTI files:  17%|█▋        | 1/6 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata found for THX AX MIP 10 8.nii.gz, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing NIfTI files:  33%|███▎      | 2/6 [00:00<00:01,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata found for THX BB COR 3 3.nii.gz, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing NIfTI files:  67%|██████▋   | 4/6 [00:01<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata found for THX BB SAG 3 3.nii.gz, skipping\n",
      "No metadata found for MIP 10 8 AXIAL.nii.gz, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing NIfTI files:  83%|████████▎ | 5/6 [00:02<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metadata found for Thorax_lever 1.25_1.25.nii.gz, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing NIfTI files: 100%|██████████| 6/6 [00:26<00:00,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed file at C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\NIFTI PRE CT SCANS\\Downloaded\\train_10019_a_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_root = r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\"\n",
    "root_nifti_dir = r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\NIFTI CT SCANS\"\n",
    "metadata_csv_path = r\"C:\\Users\\20203686\\Downloads\\train_metadata.csv\"\n",
    "\n",
    "# Load metadata\n",
    "df = pd.read_csv(metadata_csv_path)\n",
    "\n",
    "def read_nii_files(directory):\n",
    "    nii_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.nii.gz'):\n",
    "                nii_files.append(os.path.join(root, file))\n",
    "    return nii_files\n",
    "\n",
    "def read_nii_data(file_path):\n",
    "    try:\n",
    "        nii_img = nib.load(file_path)\n",
    "        nii_data = nii_img.get_fdata()\n",
    "        return nii_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def resize_array(array, current_spacing, target_spacing):\n",
    "    # array shape = (1, 1, D, H, W)\n",
    "    original_shape = array.shape[2:]  # D, H, W\n",
    "    scaling_factors = [current_spacing[i] / target_spacing[i] for i in range(len(original_shape))]\n",
    "    new_shape = [int(original_shape[i] * scaling_factors[i]) for i in range(len(original_shape))]\n",
    "    resized_array = F.interpolate(array, size=new_shape, mode='trilinear', align_corners=False).cpu().numpy()\n",
    "    return resized_array\n",
    "\n",
    "def process_file(file_path):\n",
    "    img_data = read_nii_data(file_path)\n",
    "    if img_data is None:\n",
    "        print(f\"Read {file_path} unsuccessful. Passing\")\n",
    "        return\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Get metadata row matching VolumeName (filename)\n",
    "    row = df[df['VolumeName'] == file_name]\n",
    "    if row.empty:\n",
    "        print(f\"No metadata found for {file_name}, skipping\")\n",
    "        return\n",
    "\n",
    "    slope = float(row[\"RescaleSlope\"].iloc[0])\n",
    "    intercept = float(row[\"RescaleIntercept\"].iloc[0])\n",
    "    xy_spacing = float(row[\"XYSpacing\"].iloc[0][1:-1].split(\",\")[0])\n",
    "    z_spacing = float(row[\"ZSpacing\"].iloc[0])\n",
    "\n",
    "    # Target spacings\n",
    "    target_x_spacing = 0.75\n",
    "    target_y_spacing = 0.75\n",
    "    target_z_spacing = 1.5\n",
    "\n",
    "    current_spacing = (z_spacing, xy_spacing, xy_spacing)\n",
    "    target_spacing = (target_z_spacing, target_x_spacing, target_y_spacing)\n",
    "\n",
    "    img_data = slope * img_data + intercept\n",
    "\n",
    "    hu_min, hu_max = -1000, 1000\n",
    "    img_data = np.clip(img_data, hu_min, hu_max)\n",
    "    img_data = (img_data / 1000).astype(np.float32)\n",
    "\n",
    "    tensor = torch.tensor(img_data).unsqueeze(0).unsqueeze(0)\n",
    "    resized_array = resize_array(tensor, current_spacing, target_spacing)\n",
    "    resized_array = resized_array[0, 0]\n",
    "\n",
    "    patient_id = os.path.basename(os.path.dirname(file_path))\n",
    "\n",
    "    # Create patient folder inside main save folder\n",
    "    save_folder = os.path.join(base_root, \"NIFTI PRE CT SCANS\", patient_id)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "    npz_name = file_name.replace('.nii.gz', '.npz')\n",
    "    save_path = os.path.join(save_folder, npz_name)\n",
    "    np.savez_compressed(save_path, resized_array)\n",
    "    print(f\"Saved preprocessed file at {save_path}\")\n",
    "\n",
    "\n",
    "# Get all NIfTI files\n",
    "nifti_files = read_nii_files(root_nifti_dir)\n",
    "\n",
    "for f in tqdm(nifti_files, desc=\"Preprocessing NIfTI files\"):\n",
    "    process_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea896b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformer_maskgit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mctvit\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mct_clip\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CTCLIP\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Sigmoid function\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20203686\\Documents\\GitHub\\CT-CLIP\\CT_CLIP\\ctvit.py:20\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01meinops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Rearrange\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvector_quantize_pytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorQuantize\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_maskgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Attention, Transformer, ContinuousPositionBias\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# helpers\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexists\u001b[39m(val):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformer_maskgit'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from transformer_maskgit import CTViT\n",
    "from ct_clip import CTCLIP\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(tensor):\n",
    "    return 1 / (1 + torch.exp(-tensor))\n",
    "\n",
    "# Classifier model\n",
    "class ImageLatentsClassifier(nn.Module):\n",
    "    def __init__(self, trained_model, latent_dim, num_classes, dropout_prob=0.3):\n",
    "        super(ImageLatentsClassifier, self).__init__()\n",
    "        self.trained_model = trained_model\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, latents=False, *args, **kwargs):\n",
    "        kwargs['return_latents'] = True\n",
    "        _, image_latents = self.trained_model(*args, **kwargs)\n",
    "        image_latents = self.relu(image_latents)\n",
    "        if latents:\n",
    "            return image_latents\n",
    "        image_latents = self.dropout(image_latents)\n",
    "        return self.classifier(image_latents)\n",
    "\n",
    "# Custom dataset for inference\n",
    "class CTReportDatasetinfer(Dataset):\n",
    "    def __init__(self, data_folder, csv_file, labels_csv):\n",
    "        \"\"\"\n",
    "        data_folder: Directory containing .npz files (e.g., 'NIFTI PRE CT SCANS')\n",
    "        csv_file: Path to metadata.csv\n",
    "        labels_csv: Path to CSV with pathology labels (PatientID, ScanName, and 18 pathology columns)\n",
    "        \"\"\"\n",
    "        self.data_folder = data_folder\n",
    "        self.metadata = pd.read_csv(csv_file)\n",
    "        self.labels_df = pd.read_csv(labels_csv)\n",
    "        self.npz_files = []\n",
    "        for root, _, files in os.walk(data_folder):\n",
    "            for file in files:\n",
    "                if file.endswith('.npz'):\n",
    "                    self.npz_files.append(os.path.join(root, file))\n",
    "        self.pathologies = ['Medical material', 'Arterial wall calcification', 'Cardiomegaly', 'Pericardial effusion',\n",
    "                            'Coronary artery wall calcification', 'Hiatal hernia', 'Lymphadenopathy', 'Emphysema',\n",
    "                            'Atelectasis', 'Lung nodule', 'Lung opacity', 'Pulmonary fibrotic sequela',\n",
    "                            'Pleural effusion', 'Mosaic attenuation pattern', 'Peribronchial thickening',\n",
    "                            'Consolidation', 'Bronchiectasis', 'Interlobular septal thickening']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npz_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        npz_path = self.npz_files[idx]\n",
    "        patient_id = os.path.basename(os.path.dirname(npz_path))\n",
    "        scan_name = os.path.basename(npz_path).replace('.npz', '')\n",
    "        \n",
    "        # Load .npz file\n",
    "        data = np.load(npz_path)\n",
    "        img_data = data['arr_0'].astype(np.float32)\n",
    "        \n",
    "        # Resize to (480, 480, 480)\n",
    "        target_shape = (480, 480, 480)\n",
    "        img_data = self.resize_volume(img_data, target_shape)\n",
    "        \n",
    "        # Convert to tensor and add channel dimension\n",
    "        img_tensor = torch.tensor(img_data).unsqueeze(0)  # Shape: (1, D, H, W)\n",
    "        \n",
    "        # Get labels from labels_csv\n",
    "        label_row = self.labels_df[(self.labels_df['PatientID'] == patient_id) & \n",
    "                                  (self.labels_df['ScanName'] == scan_name)]\n",
    "        if label_row.empty:\n",
    "            labels = torch.zeros(len(self.pathologies), dtype=torch.float32)\n",
    "        else:\n",
    "            labels = torch.tensor(label_row[self.pathologies].values, dtype=torch.float32).squeeze()\n",
    "        \n",
    "        # Accession number (use PatientID_ScanName as unique identifier)\n",
    "        acc_no = f\"{patient_id}_{scan_name}\"\n",
    "        \n",
    "        return img_tensor, None, labels, acc_no\n",
    "\n",
    "    def resize_volume(self, volume, target_shape):\n",
    "        \"\"\"\n",
    "        Resize 3D volume to target shape using trilinear interpolation.\n",
    "        \"\"\"\n",
    "        volume_tensor = torch.tensor(volume).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, D, H, W)\n",
    "        resized = F.interpolate(volume_tensor, size=target_shape, mode='trilinear', align_corners=False)\n",
    "        return resized.squeeze().numpy()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(args, model, dataloader, device):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    predictedall = []\n",
    "    realall = []\n",
    "    accs = []\n",
    "    pathologies = ['Medical material', 'Arterial wall calcification', 'Cardiomegaly', 'Pericardial effusion',\n",
    "                   'Coronary artery wall calcification', 'Hiatal hernia', 'Lymphadenopathy', 'Emphysema',\n",
    "                   'Atelectasis', 'Lung nodule', 'Lung opacity', 'Pulmonary fibrotic sequela',\n",
    "                   'Pleural effusion', 'Mosaic attenuation pattern', 'Peribronchial thickening',\n",
    "                   'Consolidation', 'Bronchiectasis', 'Interlobular septal thickening']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, _, labels, acc_no = batch\n",
    "            labels = labels.float().to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            text_tokens = tokenizer(\"\", return_tensors=\"pt\", padding=\"max_length\", \n",
    "                                  truncation=True, max_length=200).to(device)\n",
    "            output = model(False, text_tokens, inputs, device=device)\n",
    "            predicted = sigmoid(output).cpu().numpy()[0]\n",
    "            predictedall.append(predicted)\n",
    "            realall.append(labels.cpu().numpy()[0])\n",
    "            accs.append(acc_no[0])\n",
    "            print(f\"Accession: {acc_no[0]}\", flush=True)\n",
    "\n",
    "    # Save results\n",
    "    plotdir = args.save\n",
    "    os.makedirs(plotdir, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{plotdir}/accessions.txt\", \"w\") as file:\n",
    "        for item in accs:\n",
    "            file.write(f\"{item}\\n\")\n",
    "\n",
    "    predictedall = np.array(predictedall)\n",
    "    realall = np.array(realall)\n",
    "    \n",
    "    np.savez(f\"{plotdir}/labels_weights.npz\", data=realall)\n",
    "    np.savez(f\"{plotdir}/predicted_weights.npz\", data=predictedall)\n",
    "\n",
    "    # Generate classification report\n",
    "    predicted_binary = (predictedall > 0.5).astype(int)\n",
    "    report = classification_report(realall, predicted_binary, target_names=pathologies, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Save AUROC and classification report\n",
    "    writer = pd.ExcelWriter(f'{plotdir}/aurocs.xlsx', engine='xlsxwriter')\n",
    "    report_df.to_excel(writer, sheet_name='Classification Report')\n",
    "    writer.close()\n",
    "\n",
    "    print(\"Evaluation complete. Results saved to:\", plotdir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Parse arguments\n",
    "    parser = argparse.ArgumentParser(description=\"Inference for CT pathology classification\")\n",
    "    parser.add_argument('--data_folder', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\NIFTI PRE CT SCANS\",\n",
    "                        help=\"Path to preprocessed .npz files\")\n",
    "    parser.add_argument('--reports_file', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\metadata.csv\",\n",
    "                        help=\"Path to metadata CSV\")\n",
    "    parser.add_argument('--labels', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\labels.csv\",\n",
    "                        help=\"Path to labels CSV\")\n",
    "    parser.add_argument('--pretrained', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\CT-CLIP\\CT_VocabFine_v2.pt\",\n",
    "                        help=\"Path to pretrained model checkpoint\")\n",
    "    parser.add_argument('--save', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\results\",\n",
    "                        help=\"Directory to save results\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Initialize tokenizer and models\n",
    "    tokenizer = BertTokenizer.from_pretrained('microsoft/BiomedVLP-CXR-BERT-specialized', do_lower_case=True)\n",
    "    text_encoder = BertModel.from_pretrained(\"microsoft/BiomedVLP-CXR-BERT-specialized\")\n",
    "    text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    image_encoder = CTViT(\n",
    "        dim=512,\n",
    "        codebook_size=8192,\n",
    "        image_size=480,\n",
    "        patch_size=20,\n",
    "        temporal_patch_size=10,\n",
    "        spatial_depth=4,\n",
    "        temporal_depth=4,\n",
    "        dim_head=32,\n",
    "        heads=8\n",
    "    )\n",
    "\n",
    "    clip = CTCLIP(\n",
    "        image_encoder=image_encoder,\n",
    "        text_encoder=text_encoder,\n",
    "        dim_image=294912,\n",
    "        dim_text=768,\n",
    "        dim_latent=512,\n",
    "        extra_latent_projection=False,\n",
    "        use_mlm=False,\n",
    "        downsample_image_embeds=False,\n",
    "        use_all_token_embeds=False\n",
    "    )\n",
    "\n",
    "    num_classes = 18\n",
    "    image_classifier = ImageLatentsClassifier(clip, 512, num_classes)\n",
    "    \n",
    "    # Load pretrained weights\n",
    "    image_classifier.load(args.pretrained)\n",
    "\n",
    "    # Prepare dataset and dataloader\n",
    "    ds = CTReportDatasetinfer(data_folder=args.data_folder, csv_file=args.reports_file, labels_csv=args.labels)\n",
    "    dl = DataLoader(ds, num_workers=8, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluate_model(args, image_classifier, dl, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90eedc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
