{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2100f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformer_maskgit.MaskGITTransformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_maskgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_maskgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mctvit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CTViT\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mct_clip\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CTCLIP\n",
      "File \u001b[1;32mc:\\Users\\20203686\\Documents\\GitHub\\CT-CLIP\\transformer_maskgit\\transformer_maskgit\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_maskgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMaskGITTransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaskGITTransformer, CTViT, MaskGit, TokenCritic, make_video\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_maskgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideotextdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoTextDataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_maskgit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mctvit_trainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CTViTTrainer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformer_maskgit.MaskGITTransformer'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_maskgit.transformer_maskgit.ctvit import CTViT\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from ct_clip import CTCLIP\n",
    "from zero_shot import CTClipInference\n",
    "import accelerate\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('microsoft/BiomedVLP-CXR-BERT-specialized',do_lower_case=True)\n",
    "text_encoder = BertModel.from_pretrained(\"microsoft/BiomedVLP-CXR-BERT-specialized\")\n",
    "\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "image_encoder = CTViT(\n",
    "    dim = 512,\n",
    "    codebook_size = 8192,\n",
    "    image_size = 480,\n",
    "    patch_size = 20,\n",
    "    temporal_patch_size = 10,\n",
    "    spatial_depth = 4,\n",
    "    temporal_depth = 4,\n",
    "    dim_head = 32,\n",
    "    heads = 8\n",
    ")\n",
    "\n",
    "clip = CTCLIP(\n",
    "    image_encoder = image_encoder,\n",
    "    text_encoder = text_encoder,\n",
    "    dim_image = 294912,\n",
    "    dim_text = 768,\n",
    "    dim_latent = 512,\n",
    "    extra_latent_projection = False,         # whether to use separate projections for text-to-image vs image-to-text comparisons (CLOOB)\n",
    "    use_mlm=False,\n",
    "    downsample_image_embeds = False,\n",
    "    use_all_token_embeds = False\n",
    "\n",
    ")\n",
    "\n",
    "clip.load(\"path_to_pretrained_model\")\n",
    "\n",
    "inference = CTClipInference(\n",
    "    clip,\n",
    "    data_folder = 'path_to_preprocessed_validation_folder',\n",
    "    reports_file= \"path_to_validation_reports_csv\",\n",
    "    labels = \"path_to_validation_labels_csv\",\n",
    "    batch_size = 1,\n",
    "    results_folder=\"inference_zeroshot/\",\n",
    "    num_train_steps = 1,\n",
    ")\n",
    "\n",
    "inference.infer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab87ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
