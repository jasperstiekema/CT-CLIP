{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30e7944",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformer_maskgit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     15\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_maskgit\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformer_maskgit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CTViT\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mct_clip\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CTCLIP\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Sigmoid function\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformer_maskgit'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('transformer_maskgit'))\n",
    "from transformer_maskgit import CTViT\n",
    "from ct_clip import CTCLIP\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(tensor):\n",
    "    return 1 / (1 + torch.exp(-tensor))\n",
    "\n",
    "# Classifier model\n",
    "class ImageLatentsClassifier(nn.Module):\n",
    "    def __init__(self, trained_model, latent_dim, num_classes, dropout_prob=0.3):\n",
    "        super(ImageLatentsClassifier, self).__init__()\n",
    "        self.trained_model = trained_model\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.classifier = nn.Linear(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, latents=False, *args, **kwargs):\n",
    "        kwargs['return_latents'] = True\n",
    "        _, image_latents = self.trained_model(*args, **kwargs)\n",
    "        image_latents = self.relu(image_latents)\n",
    "        if latents:\n",
    "            return image_latents\n",
    "        image_latents = self.dropout(image_latents)\n",
    "        return self.classifier(image_latents)\n",
    "\n",
    "# Custom dataset for inference\n",
    "class CTReportDatasetinfer(Dataset):\n",
    "    def __init__(self, data_folder, csv_file, labels_csv):\n",
    "        \"\"\"\n",
    "        data_folder: Directory containing .npz files (e.g., 'NIFTI PRE CT SCANS')\n",
    "        csv_file: Path to metadata.csv\n",
    "        labels_csv: Path to CSV with pathology labels (PatientID, ScanName, and 18 pathology columns)\n",
    "        \"\"\"\n",
    "        self.data_folder = data_folder\n",
    "        self.metadata = pd.read_csv(csv_file)\n",
    "        self.labels_df = pd.read_csv(labels_csv)\n",
    "        self.npz_files = []\n",
    "        for root, _, files in os.walk(data_folder):\n",
    "            for file in files:\n",
    "                if file.endswith('.npz'):\n",
    "                    self.npz_files.append(os.path.join(root, file))\n",
    "        self.pathologies = ['Medical material', 'Arterial wall calcification', 'Cardiomegaly', 'Pericardial effusion',\n",
    "                            'Coronary artery wall calcification', 'Hiatal hernia', 'Lymphadenopathy', 'Emphysema',\n",
    "                            'Atelectasis', 'Lung nodule', 'Lung opacity', 'Pulmonary fibrotic sequela',\n",
    "                            'Pleural effusion', 'Mosaic attenuation pattern', 'Peribronchial thickening',\n",
    "                            'Consolidation', 'Bronchiectasis', 'Interlobular septal thickening']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.npz_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        npz_path = self.npz_files[idx]\n",
    "        patient_id = os.path.basename(os.path.dirname(npz_path))\n",
    "        scan_name = os.path.basename(npz_path).replace('.npz', '')\n",
    "        \n",
    "        # Load .npz file\n",
    "        data = np.load(npz_path)\n",
    "        img_data = data['arr_0'].astype(np.float32)\n",
    "        \n",
    "        # Resize to (480, 480, 480)\n",
    "        target_shape = (480, 480, 480)\n",
    "        img_data = self.resize_volume(img_data, target_shape)\n",
    "        \n",
    "        # Convert to tensor and add channel dimension\n",
    "        img_tensor = torch.tensor(img_data).unsqueeze(0)  # Shape: (1, D, H, W)\n",
    "        \n",
    "        # Get labels from labels_csv\n",
    "        label_row = self.labels_df[(self.labels_df['PatientID'] == patient_id) & \n",
    "                                  (self.labels_df['ScanName'] == scan_name)]\n",
    "        if label_row.empty:\n",
    "            labels = torch.zeros(len(self.pathologies), dtype=torch.float32)\n",
    "        else:\n",
    "            labels = torch.tensor(label_row[self.pathologies].values, dtype=torch.float32).squeeze()\n",
    "        \n",
    "        # Accession number (use PatientID_ScanName as unique identifier)\n",
    "        acc_no = f\"{patient_id}_{scan_name}\"\n",
    "        \n",
    "        return img_tensor, None, labels, acc_no\n",
    "\n",
    "    def resize_volume(self, volume, target_shape):\n",
    "        \"\"\"\n",
    "        Resize 3D volume to target shape using trilinear interpolation.\n",
    "        \"\"\"\n",
    "        volume_tensor = torch.tensor(volume).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, D, H, W)\n",
    "        resized = F.interpolate(volume_tensor, size=target_shape, mode='trilinear', align_corners=False)\n",
    "        return resized.squeeze().numpy()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(args, model, dataloader, device):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    predictedall = []\n",
    "    realall = []\n",
    "    accs = []\n",
    "    pathologies = ['Medical material', 'Arterial wall calcification', 'Cardiomegaly', 'Pericardial effusion',\n",
    "                   'Coronary artery wall calcification', 'Hiatal hernia', 'Lymphadenopathy', 'Emphysema',\n",
    "                   'Atelectasis', 'Lung nodule', 'Lung opacity', 'Pulmonary fibrotic sequela',\n",
    "                   'Pleural effusion', 'Mosaic attenuation pattern', 'Peribronchial thickening',\n",
    "                   'Consolidation', 'Bronchiectasis', 'Interlobular septal thickening']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, _, labels, acc_no = batch\n",
    "            labels = labels.float().to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            text_tokens = tokenizer(\"\", return_tensors=\"pt\", padding=\"max_length\", \n",
    "                                  truncation=True, max_length=200).to(device)\n",
    "            output = model(False, text_tokens, inputs, device=device)\n",
    "            predicted = sigmoid(output).cpu().numpy()[0]\n",
    "            predictedall.append(predicted)\n",
    "            realall.append(labels.cpu().numpy()[0])\n",
    "            accs.append(acc_no[0])\n",
    "            print(f\"Accession: {acc_no[0]}\", flush=True)\n",
    "\n",
    "    # Save results\n",
    "    plotdir = args.save\n",
    "    os.makedirs(plotdir, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{plotdir}/accessions.txt\", \"w\") as file:\n",
    "        for item in accs:\n",
    "            file.write(f\"{item}\\n\")\n",
    "\n",
    "    predictedall = np.array(predictedall)\n",
    "    realall = np.array(realall)\n",
    "    \n",
    "    np.savez(f\"{plotdir}/labels_weights.npz\", data=realall)\n",
    "    np.savez(f\"{plotdir}/predicted_weights.npz\", data=predictedall)\n",
    "\n",
    "    # Generate classification report\n",
    "    predicted_binary = (predictedall > 0.5).astype(int)\n",
    "    report = classification_report(realall, predicted_binary, target_names=pathologies, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Save AUROC and classification report\n",
    "    writer = pd.ExcelWriter(f'{plotdir}/aurocs.xlsx', engine='xlsxwriter')\n",
    "    report_df.to_excel(writer, sheet_name='Classification Report')\n",
    "    writer.close()\n",
    "\n",
    "    print(\"Evaluation complete. Results saved to:\", plotdir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Parse arguments\n",
    "    parser = argparse.ArgumentParser(description=\"Inference for CT pathology classification\")\n",
    "    parser.add_argument('--data_folder', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\NIFTI PRE CT SCANS\",\n",
    "                        help=\"Path to preprocessed .npz files\")\n",
    "    parser.add_argument('--reports_file', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\metadata.csv\",\n",
    "                        help=\"Path to metadata CSV\")\n",
    "    parser.add_argument('--labels', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\labels.csv\",\n",
    "                        help=\"Path to labels CSV\")\n",
    "    parser.add_argument('--pretrained', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\CT-CLIP\\CT_VocabFine_v2.pt\",\n",
    "                        help=\"Path to pretrained model checkpoint\")\n",
    "    parser.add_argument('--save', type=str, \n",
    "                        default=r\"C:\\Users\\20203686\\OneDrive - TU Eindhoven\\TUe\\Master\\Year 2\\MASTER PROJECT\\results\",\n",
    "                        help=\"Directory to save results\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Initialize tokenizer and models\n",
    "    tokenizer = BertTokenizer.from_pretrained('microsoft/BiomedVLP-CXR-BERT-specialized', do_lower_case=True)\n",
    "    text_encoder = BertModel.from_pretrained(\"microsoft/BiomedVLP-CXR-BERT-specialized\")\n",
    "    text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    image_encoder = CTViT(\n",
    "        dim=512,\n",
    "        codebook_size=8192,\n",
    "        image_size=480,\n",
    "        patch_size=20,\n",
    "        temporal_patch_size=10,\n",
    "        spatial_depth=4,\n",
    "        temporal_depth=4,\n",
    "        dim_head=32,\n",
    "        heads=8\n",
    "    )\n",
    "\n",
    "    clip = CTCLIP(\n",
    "        image_encoder=image_encoder,\n",
    "        text_encoder=text_encoder,\n",
    "        dim_image=294912,\n",
    "        dim_text=768,\n",
    "        dim_latent=512,\n",
    "        extra_latent_projection=False,\n",
    "        use_mlm=False,\n",
    "        downsample_image_embeds=False,\n",
    "        use_all_token_embeds=False\n",
    "    )\n",
    "\n",
    "    num_classes = 18\n",
    "    image_classifier = ImageLatentsClassifier(clip, 512, num_classes)\n",
    "    \n",
    "    # Load pretrained weights\n",
    "    image_classifier.load(args.pretrained)\n",
    "\n",
    "    # Prepare dataset and dataloader\n",
    "    ds = CTReportDatasetinfer(data_folder=args.data_folder, csv_file=args.reports_file, labels_csv=args.labels)\n",
    "    dl = DataLoader(ds, num_workers=8, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluate_model(args, image_classifier, dl, torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da7eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasterProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
